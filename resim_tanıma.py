# -*- coding: utf-8 -*-
"""Resim_TanÄ±ma.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gzulr9vfmcN9nrf6hp0g5ou39zMlMvwh
"""

# Gerekli kÃ¼tÃ¼phaneleri kur
!pip install torchvision timm

import os
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split
import matplotlib.pyplot as plt
import torch

data_dir = "/content/drive/MyDrive/MultiZoo/train"  # KlasÃ¶r yolu

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])  # RGB iÃ§in 3 deÄŸer yazÄ±labilir
])

full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)

# EÄŸitim ve DoÄŸrulama setine ayÄ±r (Ã¶rneÄŸin %80 - %20)
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32)

images, labels = next(iter(train_loader))
plt.imshow(images[0].permute(1, 2, 0))  # PyTorch tensor (C, H, W) â†’ (H, W, C)
plt.title(f"SÄ±nÄ±f: {labels[0].item()}")
plt.axis('off')
plt.show()

# Unnormalize iÅŸlemi
img = images[0]
img = img * 0.5 + 0.5  # [-1,1] â†’ [0,1]
img = img.permute(1, 2, 0).numpy()

plt.imshow(img)
plt.title(f"SÄ±nÄ±f: {labels[0].item()}")
plt.axis('off')
plt.show()

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.optim import Adam
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
import timm
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
import matplotlib.pyplot as plt
from tqdm import tqdm
from PIL import Image

# âœ… Cihaz ayarÄ±
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("KullanÄ±lan cihaz:", device)

# âœ… Veri yolu
data_dir = "/content/drive/MyDrive/MultiZoo/train"

# âœ… EÄŸitim iÃ§in augmentation'lÄ± transform
train_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

# âœ… DoÄŸrulama iÃ§in basit transform
val_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

# âœ… Veri seti ve DataLoader
full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transforms)
num_classes = len(full_dataset.classes)

train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

# DoÄŸrulama seti iÃ§in transform'u gÃ¼ncelle
val_dataset.dataset.transform = val_transforms

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32)

# âœ… Model
model = timm.create_model('vit_base_patch16_224', pretrained=True, drop_rate=0.2)
model.head = nn.Linear(model.head.in_features, num_classes)
model.to(device)

# âœ… KayÄ±p fonksiyonu ve optimizer
criterion = nn.CrossEntropyLoss()
optimizer = Adam(model.parameters(), lr=1e-4)

# âœ… EÄŸitim parametreleri
epochs = 30
patience = 2
best_val_loss = float("inf")
early_stop_counter = 0

train_losses, val_losses = [], []
train_acc_list, val_acc_list = [], []
train_f1_list, val_f1_list = [], []

# ğŸ” EÄŸitim dÃ¶ngÃ¼sÃ¼
for epoch in range(epochs):
    print(f"\nğŸ” Epoch {epoch+1}/{epochs}")
    model.train()
    train_loss = 0
    y_true_train, y_pred_train = [], []

    for images, labels in tqdm(train_loader):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()

        _, predicted = torch.max(outputs, 1)
        y_true_train.extend(labels.cpu().numpy())
        y_pred_train.extend(predicted.cpu().numpy())

    train_losses.append(train_loss / len(train_loader))
    train_acc = accuracy_score(y_true_train, y_pred_train)
    train_f1 = f1_score(y_true_train, y_pred_train, average='macro')
    train_acc_list.append(train_acc)
    train_f1_list.append(train_f1)

    # âœ… DoÄŸrulama
    model.eval()
    val_loss = 0
    y_true_val, y_pred_val = [], []

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            y_true_val.extend(labels.cpu().numpy())
            y_pred_val.extend(predicted.cpu().numpy())

    val_loss_avg = val_loss / len(val_loader)
    val_losses.append(val_loss_avg)
    val_acc = accuracy_score(y_true_val, y_pred_val)
    val_f1 = f1_score(y_true_val, y_pred_val, average='macro')
    val_acc_list.append(val_acc)
    val_f1_list.append(val_f1)

    print(f"âœ… Val Accuracy: {val_acc:.4f} | Val Loss: {val_loss_avg:.4f} | Val F1: {val_f1:.4f}")
    print(f"ğŸ“ˆ Train Accuracy: {train_acc:.4f} | Train F1: {train_f1:.4f}")

    # âœ… EarlyStopping
    if val_loss_avg < best_val_loss:
        best_val_loss = val_loss_avg
        early_stop_counter = 0
        torch.save(model.state_dict(), "vit_model_best.pth")
        print("ğŸ’¾ Model kaydedildi (vit_model_best.pth)")
    else:
        early_stop_counter += 1
        print(f"âš ï¸ Early stop sayacÄ±: {early_stop_counter}/{patience}")
        if early_stop_counter >= patience:
            print("â›” EÄŸitim erken durduruldu (Early Stopping)")
            break

# âœ… Ã–ÄŸrenme EÄŸrileri
plt.plot(train_acc_list, label="Train Accuracy")
plt.plot(val_acc_list, label="Val Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Accuracy Learning Curve")
plt.legend()
plt.grid(True)
plt.show()

plt.plot(train_f1_list, label="Train F1 Score")
plt.plot(val_f1_list, label="Val F1 Score")
plt.xlabel("Epoch")
plt.ylabel("F1 Score")
plt.title("F1 Score Learning Curve")
plt.legend()
plt.grid(True)
plt.show()

plt.plot(train_losses, label="Train Loss")
plt.plot(val_losses, label="Val Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Loss Learning Curve")
plt.legend()
plt.grid(True)
plt.show()

# âœ… DeÄŸerlendirme
model.load_state_dict(torch.load("vit_model_best.pth"))
model.eval()
y_true, y_pred = [], []

with torch.no_grad():
    for images, labels in val_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        y_true.extend(labels.cpu().numpy())
        y_pred.extend(predicted.cpu().numpy())

accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred, average='macro')
recall = recall_score(y_true, y_pred, average='macro')
f1 = f1_score(y_true, y_pred, average='macro')

print(f"\nğŸ” Accuracy  : {accuracy:.4f}")
print(f"ğŸ“Œ Precision : {precision:.4f}")
print(f"ğŸ“Œ Recall    : {recall:.4f}")
print(f"ğŸ“Œ F1-score  : {f1:.4f}\n")

class_names = full_dataset.classes
print(classification_report(y_true, y_pred, target_names=class_names))

import torch
torch.save(model.state_dict(), "vit_model_best.pth")

from google.colab import files
files.download("vit_model_best.pth")